{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59739126",
   "metadata": {},
   "source": [
    "### Group 8\n",
    "- Nimrod Grandpierre\n",
    "- Jonas Riber JÃ¸rgensen\n",
    "- Johan Ulstrup\n",
    "- Laura Fur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87975f9b",
   "metadata": {},
   "source": [
    "# Project 5: NJ tree construction\n",
    "This project is about making an efficient implementation of the neighbor-joining (NJ) algorithm as shown on slide 50 in the slides about tree reconstruction and compare its performance to the NJ programs QuickTree and RapidNJ that you know from project 4.\n",
    "\n",
    "## <span style=\"color:cornflowerblue\">Problem<span/>\n",
    "You should make a program that implements the NJ algorithm as shown in the slides about tree reconstruction. Your program program should take a distance matrix in phylip-format as input and produce a tree in newick-format as output. You should know these formats from project 4. Your aim is to make your implementation as efficient as possible.\n",
    "\n",
    "The file example_slide4.phy contains the distance matrix (in phylip-format) from slide 4 in the slides about tree reconstruction. With this matrix as input, your program should produce the tree that is also shown on slide 4 in the slides about tree reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb29b9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from read_phylip import *\n",
    "from correct_DM import *\n",
    "from NJ_print import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17606748",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6569f359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NJ(S: list, DM: dict):\n",
    "\n",
    "    T = []\n",
    "\n",
    "    while len(S) > 3:\n",
    "\n",
    "        def cluster(S, DM):\n",
    "            nonlocal T\n",
    "\n",
    "            \"\"\" Step 1: a) Correcting DM b) Choosing pair to cluster \"\"\"\n",
    "            N = compute_N(S, DM)\n",
    "\n",
    "            min_distances = {i: min((distance, idx) for idx, distance in enumerate(row) if distance != 0.0) for i, row in N.items()}  # Finding the shortest distance and its index for each sequence in N.\n",
    "            S1 = min(min_distances, key = lambda k: min_distances[k][0])                                                              # Key with the minimum value among all minimum distances.\n",
    "            S1_idx = next((i for i, seq in enumerate(DM) if seq == S1))\n",
    "            S2_idx = min_distances[S1][1]                                                                                             # Extract the index of the second sequence. \n",
    "            S2 = S[S2_idx]                                                                                                            # Get name for the second sequence from S.\n",
    "\n",
    "            k = [S1, S2]\n",
    "\n",
    "            \"\"\" Step 2: Adding new node, k, to T \"\"\"\n",
    "            k_copy = k.copy()  # Create a copy of k to avoid overwriting.\n",
    "            T.append(k_copy)   # Append the copy to T\n",
    "\n",
    "            \"\"\" Step 3: Calculating distances to new cluster and adding edges, (k, i) and (k, j) \"\"\"\n",
    "            \n",
    "            # Adding edges:\n",
    "            dij = {seq_i: DM[seq_i] for seq_i in DM.keys()}\n",
    "            ri = {seq_i: round((1 / (len(DM) - 2)) * np.sum(DM_i), 2) for i, (seq_i, DM_i) in enumerate(DM.items()) for j in range(len(DM_i)) if i != j}\n",
    "            \n",
    "            diu = round(0.5 * dij[S1][S2_idx] + 0.5 * (ri[S1] - ri[S2]), 2)      # Distance from S1 to common node in cluster.\n",
    "            dju = round(dij[S1][S2_idx] - diu, 2)                                # Distance from S2 to common node in cluster.\n",
    "\n",
    "            cluster_idx = T.index(k)\n",
    "            T[cluster_idx].append(diu)\n",
    "            T[cluster_idx].append(dju)\n",
    "\n",
    "            # Calculating distances from other sequences to the new cluster:\n",
    "            dijk = {}\n",
    "            for i, seq_i in enumerate(DM.keys()):\n",
    "                if seq_i not in (S1, S2):\n",
    "                    dik = DM[S1][i]\n",
    "                    djk = DM[S2][i]\n",
    "                    dij = DM[S1][S2_idx]\n",
    "                    dijk[seq_i] = round(0.5 * (dik + djk - dij), 2)\n",
    "                dijk[(S1, S2)] = 0                                               # Converting cluster list to tuple, as lists are not allowed as keys.\n",
    "\n",
    "            \"\"\" Step 4: Update distance matrix \"\"\"\n",
    "            UDM = DM.copy()                                                      # Creating temporary distance matrix.\n",
    "            UDM[(S1, S2)] = UDM.pop(S1)                                          # Overwrite key for first sequence. Note that this puts the (S1, S2) key in the last position of the dictionary.\n",
    "\n",
    "            del UDM[S2]                                                          # Delete key for the second sequence.\n",
    "\n",
    "            for seq, dists in UDM.items():\n",
    "                UDM[seq] = np.delete(dists, list(DM.keys()).index(S2))           # Delete column for the second sequence.\n",
    "            \n",
    "            DM_idxs = {seq_i: i for i, seq_i in enumerate(DM.keys())}            # Sequence indexes in the input distance matrix.\n",
    "\n",
    "            for i, seq_i in enumerate(UDM.keys()):\n",
    "                if seq_i != (S1, S2):\n",
    "                    for j, seq_j in enumerate(UDM.keys()):\n",
    "                        if seq_j != seq_i:\n",
    "                            if seq_j == (S1, S2):\n",
    "                                UDM[seq_i][j] = dijk[seq_i]                      # Distance to k.\n",
    "                            if seq_j != (S1, S2):\n",
    "                                UDM[seq_i][j] = DM[seq_i][DM_idxs[seq_j]]        # Distance to other sequence.\n",
    "                        if seq_j == seq_i:\n",
    "                            UDM[seq_i][j] = 0                                    # Distance to self - always 0.\n",
    "                if seq_i == (S1, S2):\n",
    "                    for j, seq_j in enumerate(UDM.keys()):\n",
    "                        UDM[seq_i][j] = dijk[seq_j]                              # Distances from k.\n",
    "                                        \n",
    "            \"\"\" Step 5: Delete i and j from S and add the new taxon, k, to S. \"\"\"\n",
    "            \n",
    "            S.remove(S1)\n",
    "            S.remove(S2)\n",
    "            S.append((S1, S2))\n",
    "\n",
    "            return S, UDM, k\n",
    "\n",
    "        S, DM, k = cluster(S, DM)  # k is the last cluster formed.\n",
    "\n",
    "    \"\"\" Termination \"\"\"\n",
    "    i, j, m = S\n",
    "\n",
    "    # Ensure m is k, otherwise swap the variable that is k for m.\n",
    "    if m != tuple(k):\n",
    "        if i == tuple(k):\n",
    "            i, m = m, i\n",
    "        elif j == k:\n",
    "            j, m = m, j\n",
    "\n",
    "    idx_i = list(DM.keys()).index(i)\n",
    "    idx_j = list(DM.keys()).index(j)\n",
    "    idx_m = list(DM.keys()).index(m)\n",
    "\n",
    "    gamma_vi = round((DM[i][idx_j] + DM[i][idx_m] - DM[j][idx_m])/2, 3)\n",
    "    gamma_vj = round((DM[j][idx_i] + DM[j][idx_m] - DM[i][idx_m])/2, 3)\n",
    "    gamma_vm = round((DM[m][idx_i] + DM[m][idx_j] - DM[i][idx_j])/2, 3)\n",
    "\n",
    "    T.append([i, gamma_vi])\n",
    "    T.append([j, gamma_vj])\n",
    "    T.append([m, gamma_vm])\n",
    "\n",
    "    return T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5efdd1",
   "metadata": {},
   "source": [
    "## <span style = 'color:cornflowerblue'>Tests<span/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d778b75",
   "metadata": {},
   "source": [
    "Simple testdata with four sequences from ```wiki_ex.phy```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb88703b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[96mInitialization\u001b[0m\n",
      "\u001b[1mNo. taxa:\u001b[0m          4\n",
      "\u001b[1mTaxa:\u001b[0m              ['A', 'B', 'C', 'D']\n",
      "\u001b[1mDM:\u001b[0m                {'A': array([ 0., 17., 21., 27.]), 'B': array([17.,  0., 12., 18.]), 'C': array([21., 12.,  0., 14.]), 'D': array([27., 18., 14.,  0.])}\n",
      "\u001b[1mCorrected DM:\u001b[0m      {'A': array([  0., -39., -35., -35.]), 'B': array([-39.,   0., -35., -35.]), 'C': array([-35., -35.,   0., -39.]), 'D': array([-35., -35., -39.,   0.])}\n",
      "\u001b[1mPair to cluster:\u001b[0m   ['A', 'B'] \n",
      "\n",
      "\u001b[1m\u001b[95mClustering\u001b[0m\n",
      "\u001b[1mDistance to node:\u001b[0m  A: 13.0   B: 4.0\n",
      "\u001b[1mDistance to k:\u001b[0m     {('A', 'B'): 0, 'C': 8.0, 'D': 14.0}\n",
      "\u001b[1mOverwrite S1:\u001b[0m      {'B': array([17.,  0., 12., 18.]), 'C': array([21., 12.,  0., 14.]), 'D': array([27., 18., 14.,  0.]), ('A', 'B'): array([ 0., 17., 21., 27.])}\n",
      "\u001b[1mDelete S2:\u001b[0m         {'C': array([21.,  0., 14.]), 'D': array([27., 14.,  0.]), ('A', 'B'): array([ 0., 21., 27.])}\n",
      "\u001b[1mUpdated DM:\u001b[0m        {'C': array([ 0., 14.,  8.]), 'D': array([14.,  0., 14.]), ('A', 'B'): array([ 8., 14.,  0.])} \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['A', 'B', 13.0, 4.0], ['C', 4.0], ['D', 10.0], [('A', 'B'), 4.0]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_ex = initiate_DM('wiki_ex.phy')\n",
    "wiki_ex_taxa = [i for i in wiki_ex.keys()]\n",
    "\n",
    "wiki_ex_out = NJ_print(wiki_ex_taxa, wiki_ex)\n",
    "wiki_ex_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c77ed3",
   "metadata": {},
   "source": [
    "For this example dataset, the Newick format should look like this:\n",
    "\n",
    "(C: 4.0, D: 10.0,(A: 13.0, B: 4.0): 4.0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5f27ee",
   "metadata": {},
   "source": [
    "Provided testdata with five sequences from ```example_slide4.phy```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99f70278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[96mInitialization\u001b[0m\n",
      "\u001b[1mNo. taxa:\u001b[0m          5\n",
      "\u001b[1mTaxa:\u001b[0m              ['A', 'B', 'C', 'D', 'E']\n",
      "\u001b[1mDM:\u001b[0m                {'A': array([0.  , 0.23, 0.16, 0.2 , 0.17]), 'B': array([0.23, 0.  , 0.23, 0.17, 0.24]), 'C': array([0.16, 0.23, 0.  , 0.2 , 0.11]), 'D': array([0.2 , 0.17, 0.2 , 0.  , 0.21]), 'E': array([0.17, 0.24, 0.11, 0.21, 0.  ])}\n",
      "\u001b[1mCorrected DM:\u001b[0m      {'A': array([ 0.  , -0.31, -0.32, -0.31, -0.32]), 'B': array([-0.31,  0.  , -0.29, -0.38, -0.29]), 'C': array([-0.32, -0.29,  0.  , -0.29, -0.36]), 'D': array([-0.31, -0.38, -0.29,  0.  , -0.29]), 'E': array([-0.32, -0.29, -0.36, -0.29,  0.  ])}\n",
      "\u001b[1mPair to cluster:\u001b[0m   ['B', 'D'] \n",
      "\n",
      "\u001b[1m\u001b[95mClustering\u001b[0m\n",
      "\u001b[1mDistance to node:\u001b[0m  B: 0.1   D: 0.07\n",
      "\u001b[1mDistance to k:\u001b[0m     {'A': 0.13, ('B', 'D'): 0, 'C': 0.13, 'E': 0.14}\n",
      "\u001b[1mOverwrite S1:\u001b[0m      {'A': array([0.  , 0.23, 0.16, 0.2 , 0.17]), 'C': array([0.16, 0.23, 0.  , 0.2 , 0.11]), 'D': array([0.2 , 0.17, 0.2 , 0.  , 0.21]), 'E': array([0.17, 0.24, 0.11, 0.21, 0.  ]), ('B', 'D'): array([0.23, 0.  , 0.23, 0.17, 0.24])}\n",
      "\u001b[1mDelete S2:\u001b[0m         {'A': array([0.  , 0.23, 0.16, 0.17]), 'C': array([0.16, 0.23, 0.  , 0.11]), 'E': array([0.17, 0.24, 0.11, 0.  ]), ('B', 'D'): array([0.23, 0.  , 0.23, 0.24])}\n",
      "\u001b[1mUpdated DM:\u001b[0m        {'A': array([0.  , 0.16, 0.17, 0.13]), 'C': array([0.16, 0.  , 0.11, 0.13]), 'E': array([0.17, 0.11, 0.  , 0.14]), ('B', 'D'): array([0.13, 0.13, 0.14, 0.  ])} \n",
      "\n",
      "\u001b[1m\u001b[96mInitialization\u001b[0m\n",
      "\u001b[1mNo. taxa:\u001b[0m          4\n",
      "\u001b[1mTaxa:\u001b[0m              ['A', 'C', 'E', ('B', 'D')]\n",
      "\u001b[1mDM:\u001b[0m                {'A': array([0.  , 0.16, 0.17, 0.13]), 'C': array([0.16, 0.  , 0.11, 0.13]), 'E': array([0.17, 0.11, 0.  , 0.14]), ('B', 'D'): array([0.13, 0.13, 0.14, 0.  ])}\n",
      "\u001b[1mCorrected DM:\u001b[0m      {'A': array([ 0.  , -0.27, -0.27, -0.3 ]), 'C': array([-0.27,  0.  , -0.3 , -0.27]), 'E': array([-0.27, -0.3 ,  0.  , -0.27]), ('B', 'D'): array([-0.3 , -0.27, -0.27,  0.  ])}\n",
      "\u001b[1mPair to cluster:\u001b[0m   ['A', ('B', 'D')] \n",
      "\n",
      "\u001b[1m\u001b[95mClustering\u001b[0m\n",
      "\u001b[1mDistance to node:\u001b[0m  A: 0.08   ('B', 'D'): 0.05\n",
      "\u001b[1mDistance to k:\u001b[0m     {('A', ('B', 'D')): 0, 'C': 0.08, 'E': 0.09}\n",
      "\u001b[1mOverwrite S1:\u001b[0m      {'C': array([0.16, 0.  , 0.11, 0.13]), 'E': array([0.17, 0.11, 0.  , 0.14]), ('B', 'D'): array([0.13, 0.13, 0.14, 0.  ]), ('A', ('B', 'D')): array([0.  , 0.16, 0.17, 0.13])}\n",
      "\u001b[1mDelete S2:\u001b[0m         {'C': array([0.16, 0.  , 0.11]), 'E': array([0.17, 0.11, 0.  ]), ('A', ('B', 'D')): array([0.  , 0.16, 0.17])}\n",
      "\u001b[1mUpdated DM:\u001b[0m        {'C': array([0.  , 0.11, 0.08]), 'E': array([0.11, 0.  , 0.09]), ('A', ('B', 'D')): array([0.08, 0.09, 0.  ])} \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['B', 'D', 0.1, 0.07],\n",
       " ['A', ('B', 'D'), 0.08, 0.05],\n",
       " ['C', 0.05],\n",
       " ['E', 0.06],\n",
       " [('A', ('B', 'D')), 0.03]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slide4_ex = initiate_DM('example_slide4.phy')\n",
    "slide4_ex_taxa = [i for i in slide4_ex.keys()]\n",
    "\n",
    "slide4_ex_out = NJ_print(slide4_ex_taxa, slide4_ex)\n",
    "slide4_ex_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc3f815",
   "metadata": {},
   "source": [
    "For this example dataset, the Newick format should look like this:\n",
    "\n",
    "(C: 0.5000, E: 0.6000, (A: 0.8000, (B: 1.0000, D: 0.7000): 0.5000): 0.3000);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b93d325",
   "metadata": {},
   "source": [
    "## <span style = 'color:cornflowerblue'>Experiments<span/>\n",
    "From project 4, you know the programs QuickTree and RapidNJ that are implementations of the NJ methods. QuickTree implements the basic cubic time algorithm while RapidNJ implements an algorithm the is faster in practice.\n",
    "\n",
    "You should compare the performance of your program against these two program in the following way.\n",
    "\n",
    "The archive unique_distance_matrices.zip contains 14 distance matrices (in phylip-format) ranging in size from 89 to 1849 species. For each distance matrix, you should do the following:\n",
    "\n",
    "1. Measure the time it takes to construct the corresponding NJ tree using QuickTree, RapidNJ, and your program.\n",
    "2. Compute the RF-distances (using your program rfdist from project 4) between the trees produced by QuickTree, RapidNJ, and your program.\n",
    "\n",
    "(If you want to investigate the running time of your program on more examples than provided in distance_matrices.zip, then you are welcome to download pfam_alignments.zip that contains 128 of alignment in Stockholm-format (from the Pfam database) aligning from 58 to 71535 species that you can convert to distance matrices in phylip-format using e.g. QuickTree. However, converting the big alignments to distance matrices would probably take too long and require too much space.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a023acf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueDistMatrices = sorted([file for file in os.listdir('unique_distance_matrices')], key=lambda x: int(x.split('_')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3f0b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = initiate_DM(f'unique_distance_matrices/{uniqueDistMatrices[1]}')\n",
    "data_taxa = [i for i in data.keys()]\n",
    "\n",
    "NJ(data_taxa, data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
